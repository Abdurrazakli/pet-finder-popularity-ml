{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning Project (UT)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "!pip install -q plotnine\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "1) **Input Data** - for importing our train and test data set.\n",
    "\n",
    "2) **Data Exploration** - for exploring our train data set \n",
    "\n",
    "3) **Feature Engineering** - for merging and removing columns\n",
    "\n",
    "4) **Data Processing** - preparing data for model fitting\n",
    "\n",
    "5) **Building Models:**\n",
    "\n",
    "    1. Logistic Regression\n",
    "\n",
    "    2. Random Forest Classifier\n",
    "\n",
    "    3. KNN Classifier\n",
    "\n",
    "    4. SVC\n",
    "\n",
    "    5. XGBClassifier\n",
    "\n",
    "    6. Neural Network\n",
    "6) **Ensemble Learning** - Soft voting for final \n",
    "\n",
    "7) **Performance metrics** - for advanced measurement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('inputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./inputs/train.csv\")\n",
    "test_df = pd.read_csv(\"./inputs/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train data is {train_df.shape[0]} rows, with {train_df.shape[1]} columns\")\n",
    "print(f\"Test data is {test_df.shape[0]} rows, with {test_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = train_df[['Age','SibSp','Parch','Fare']]\n",
    "categorical_columns = train_df[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numeric_columns.columns:\n",
    "    plt.hist(numeric_columns[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train_df, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train_df, index = 'Survived', columns = 'Pclass', values = 'PassengerId' ,aggfunc ='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train_df, index = 'Survived', columns = 'Sex', values = 'PassengerId' ,aggfunc ='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train_df, index = 'Survived', columns = 'Embarked', values = 'PassengerId' ,aggfunc ='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for place in train_df['Embarked'].unique()[0:3]:\n",
    "    place_count = len(train_df[(train_df.Embarked == place)])\n",
    "    a = len(train_df)\n",
    "    print(f\"Number of people from {place} are {place_count*100/a}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Parent Children and Sibling Spouse to FamilyOnBoard\n",
    "train_df['FamilyOnBoard']= train_df.SibSp + train_df.Parch\n",
    "test_df['FamilyOnBoard']= test_df.SibSp + test_df.Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = train_df.plot.scatter('FamilyOnBoard','Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cabin_adv'] = train_df.Cabin.apply(lambda x: str(x)[0])\n",
    "test_df['cabin_adv'] = test_df.Cabin.apply(lambda x: str(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train_df,index='Survived',columns='cabin_adv', values = 'Name', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(labels='Parch', axis=1)\n",
    "test_df = test_df.drop(labels='Parch', axis=1)\n",
    "\n",
    "train_df = train_df.drop(labels='SibSp', axis=1)\n",
    "test_df = test_df.drop(labels='SibSp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_Median(dataFrame, column, groupColumns ):\n",
    "    dataFrame[column] = dataFrame[column].fillna(dataFrame.groupby(groupColumns)[column].transform('median'))\n",
    "    return dataFrame[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,9))\n",
    "sns.histplot(train_df[\"Age\"], kde=True, palette='BuPu_r')\n",
    "plt.title('Age hist Before filling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age'] = fill_empty_Median(train_df, \"Age\", ['FamilyOnBoard', 'Sex', 'Pclass', 'Fare'])\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
    "\n",
    "test_df['Age'] = fill_empty_Median(test_df, \"Age\", ['FamilyOnBoard', 'Sex', 'Pclass', 'Fare'])\n",
    "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,9))\n",
    "sns.histplot(train_df[\"Age\"], kde=True, palette='BuPu_r')\n",
    "plt.title('Age hist After filling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(labels='Cabin', axis=1)\n",
    "test_df = test_df.drop(labels='Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.Fare = test_df.Fare.fillna(train_df.Fare.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass', \"Sex\", 'Age', \"Fare\", \"Embarked\", \"FamilyOnBoard\", 'cabin_adv', 'Survived']\n",
    "\n",
    "#split valid train set into train and validation parts\n",
    "train_df = pd.get_dummies(train_df[features])\n",
    "\n",
    "train_df, train_df_val = train_test_split(train_df, random_state = 111, test_size = 0.20)\n",
    "\n",
    "y = train_df[\"Survived\"]\n",
    "x = train_df.drop(columns=['Survived'])\n",
    "\n",
    "y_val = train_df_val[\"Survived\"]\n",
    "x_val = train_df_val.drop(columns=['Survived'])\n",
    "\n",
    "features.remove(\"Survived\")\n",
    "\n",
    "test_x = pd.get_dummies(test_df[features])\n",
    "test_x.insert(16, 'cabin_adv_T' ,418*[0]) # Solution for (X has 17 features, but LogisticRegression is expecting 18 features as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=2000)\n",
    "cv = cross_val_score(lr,x,y,cv=5)\n",
    "\n",
    "print('-'*40)\n",
    "for val in enumerate(cv):\n",
    "    print(f\"Accuracy #{val[0]}: {val[1]} \")\n",
    "\n",
    "print('-'*40)\n",
    "print(f\"Mean value: {cv.mean()}\")\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,x,y,cv=5)\n",
    "\n",
    "print('-'*40)\n",
    "for val in enumerate(cv):\n",
    "    print(f\"Accuracy #{val[0]}: {val[1]} \")\n",
    "\n",
    "print('-'*40)\n",
    "print(f\"Mean value: {cv.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\n",
    "\n",
    "cv = cross_val_score(rfc, x, y, cv=5)\n",
    "\n",
    "print('-'*40)\n",
    "for val in enumerate(cv):\n",
    "    print(f\"Accuracy #{val[0]}: {val[1]} \")\n",
    "\n",
    "print('-'*40)\n",
    "print(f\"Mean value: {cv.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability = True)\n",
    "cv = cross_val_score(svc,x,y,cv=5)\n",
    "\n",
    "print('-'*40)\n",
    "for val in enumerate(cv):\n",
    "    print(f\"Accuracy #{val[0]}: {val[1]} \")\n",
    "\n",
    "print('-'*40)\n",
    "print(f\"Mean value: {cv.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state =1)\n",
    "cv = cross_val_score(xgb,x,y,cv=5)\n",
    "\n",
    "print('-'*40)\n",
    "for val in enumerate(cv):\n",
    "    print(f\"Accuracy #{val[0]}: {val[1]} \")\n",
    "\n",
    "print('-'*40)\n",
    "print(f\"Mean value: {cv.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Neural Network\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "n_features = x.columns.size\n",
    "model.add(Dense(n_features, activation='relu', input_shape=(n_features,)))\n",
    "\n",
    "model.add(Dense(n_features, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model._estimator_type = \"classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=50, batch_size=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Learning\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators = \n",
    "                              [\n",
    "                                  ('lr', lr),\n",
    "                                  ('knn',knn),\n",
    "                                  ('svc',svc),\n",
    "                                  ('xgb',xgb),\n",
    "                                  ], voting = 'soft') \n",
    "\n",
    "cv = cross_val_score(voting_clf,x,y,cv=5)\n",
    "\n",
    "print('-'*40)\n",
    "for val in enumerate(cv):\n",
    "    print(f\"Accuracy #{val[0]}: {val[1]} \")\n",
    "\n",
    "print('-'*40)\n",
    "print(f\"Mean value: {cv.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_submit(model, test_x, file_name):\n",
    "    model.fit(x,y)\n",
    "    results =  model.predict(test_x).astype(int)\n",
    "    final_data = {'PassengerId': test_df.PassengerId, 'Survived': results}\n",
    "    submission = pd.DataFrame(data=final_data)\n",
    "    submission.to_csv(f'./outputs/{file_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_submit(voting_clf, test_x, 'submission_ensemble' )\n",
    "results_to_submit(lr, test_x, 'submission_lr' )\n",
    "results_to_submit(knn, test_x, 'submission_knn' )\n",
    "results_to_submit(svc, test_x, 'submission_svc' )\n",
    "results_to_submit(xgb, test_x, 'submission_xgb' )\n",
    "results_to_submit(rfc, test_x, 'submission_rf' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,y)\n",
    "predictions =  model.predict(test_x)\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions\n",
    "\n",
    "submission = pd.read_csv('./inputs/submission_sample.csv')\n",
    "submission['Survived'] = predictions\n",
    "submission.to_csv('./outputs/submission_neural.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coordinates(scores, classes, verbose = True):\n",
    "  # thresholds can be obtained from scores\n",
    "  thresholds = np.unique(scores)\n",
    "  # initialise roc_coordinates\n",
    "  roc_coordinates = pd.DataFrame(columns=['FPR','TPR'], index=thresholds)\n",
    "\n",
    "  for threshold in thresholds:\n",
    "    if (verbose == True):\n",
    "      print(f'For threshold {threshold}')\n",
    "    \n",
    "    predictions = scores >= threshold\n",
    "    predictions[predictions == True] = 1\n",
    "    predictions[predictions == False] = 0\n",
    "    pred_positive = classes[predictions == 1].to_numpy().flatten()\n",
    "    pred_negative = classes[predictions == 0].to_numpy().flatten()\n",
    "    \n",
    "    tp = np.sum(pred_positive == 1)\n",
    "    fn = np.sum(pred_negative == 1)\n",
    "    tn = np.sum(pred_negative == 0)\n",
    "    fp = np.sum(pred_positive == 0)\n",
    "    \n",
    "    if (verbose == True):\n",
    "      print(f'tp = {tp}, fn = {fn}, tn = {tn}, fp = {fp}')\n",
    "    \n",
    "    tpr = tp/(tp + fn) # the same as recall\n",
    "    fpr = fp/(fp + tn)\n",
    "    \n",
    "    if (verbose == True):\n",
    "      print(f'FPR = {np.round(fpr, 2)}, TPR = {np.round(tpr, 2)}\\n')\n",
    "    roc_coordinates.loc[threshold] = pd.Series({'FPR':np.round(fpr,2), 'TPR':np.round(tpr,2)})\n",
    "\n",
    "  return roc_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(coordinates_dict):\n",
    "  \"\"\"\n",
    "  plot_roc function plots all models' ROCs on one plot\n",
    "  \"\"\"\n",
    "  plotting_data = pd.DataFrame(columns=['FPR', 'TPR', 'Method'])\n",
    "\n",
    "  for id, name in enumerate(coordinates_dict.keys()):\n",
    "    method_data = coordinates_dict[name]\n",
    "    method_data['Method'] = name\n",
    "    plotting_data = pd.concat([plotting_data, method_data])\n",
    "  \n",
    "  plotting_data['Method'] = pd.Categorical(plotting_data['Method'])\n",
    "  \n",
    "  # To those of you who are interested in what the hell is going on\n",
    "  # check the comments for each line:\n",
    "  roc_plot = (\n",
    "        ggplot(data = plotting_data, # creates a canvas\n",
    "        mapping = aes(x = 'FPR', y = 'TPR', colour = 'Method')) + # specifies dimensions\n",
    "        geom_path(size = 4) + # determines geometric primitive to be visualised (path/line in our case) and its thickness \n",
    "        labs(title ='', x = 'FPR', y = 'TPR') + # labels of the x and y axes\n",
    "        # this is all for the figure, beloow are only formatting specs\n",
    "        theme_bw() + # colour schema \n",
    "        theme(figure_size = (50, 50), # figure size\n",
    "              axis_line = element_line(size = 1.5, colour = \"black\"), \n",
    "              panel_grid_major = element_line(size = 0.05, colour = \"black\"),\n",
    "              panel_grid_minor = element_line(size = 0.05, colour = \"black\"),\n",
    "              axis_text = element_text(size = 70, colour ='black')) # more formatting details \n",
    "      )\n",
    "  return roc_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def show_metrics(model_list, real_survival_result):\n",
    "  for model_key in model_list:\n",
    "    print('-'*40)\n",
    "    prediction_in_use = model_list[model_key]\n",
    "    print(f\"Classification report for #{model_key}:\")\n",
    "    print(classification_report(real_survival_result, prediction_in_use))\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit all models here\n",
    "rfc.fit(x,y)\n",
    "knn.fit(x,y)\n",
    "lr.fit(x,y)\n",
    "svc.fit(x,y)\n",
    "xgb.fit(x,y)\n",
    "model.fit(x,y)\n",
    "voting_clf.fit(x,y)\n",
    "\n",
    "#Predict all models here\n",
    "rfc_prediction = rfc.predict(x_val)\n",
    "knn_prediction = knn.predict(x_val)\n",
    "lr_prediction = lr.predict(x_val)\n",
    "svc_prediction = svc.predict(x_val)\n",
    "xgb_prediction = xgb.predict(x_val)\n",
    "model_prediction = model.predict(x_val)\n",
    "voting_clf_prediction = voting_clf.predict(x_val)\n",
    "\n",
    "#Prepare list of models with predictions\n",
    "all_models_predictions = {'RandomForest':rfc_prediction, \n",
    "              'KNN':knn_prediction,\n",
    "              'LinearRegression':lr_prediction,\n",
    "              'SVC':svc_prediction,\n",
    "              'XGB':xgb_prediction,\n",
    "              'Voting':voting_clf_prediction\n",
    "              }\n",
    "\n",
    "\n",
    "show_metrics(all_models_predictions, y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_roc_coordinates(model_dict, data_X , data_Y):\n",
    "  #case of survival\n",
    "  positive_class = 1\n",
    "  val = pd.DataFrame()\n",
    "  all_roc_coordinates = {}\n",
    "  for model_key in model_dict:\n",
    "    print('-'*40)\n",
    "    print(f\"Calculationg prediction probabilities for #{model_key}:\")\n",
    "    model_in_use = model_dict[model_key] \n",
    "    val[model_key] = model_in_use.predict_proba(data_X)[:,positive_class]\n",
    "    print('-'*40)\n",
    "\n",
    "  for model_key in model_dict:\n",
    "    # passing each model's prediction probability and real survival value to function\n",
    "    # to generate roc_coordinate and put it in dictionary\n",
    "    print('-'*40)\n",
    "    print(f\"Generating ROC coordinates for #{model_key}:\")\n",
    "    all_roc_coordinates[model_key] = generate_coordinates(val[model_key].values,data_Y , verbose=False)\n",
    "    print('-'*40)\n",
    "\n",
    "  for model_key in model_dict:\n",
    "    res = np.round(metrics.roc_auc_score(data_Y,val[model_key]),3)\n",
    "    print(f\"AUC of {model_key} classifier is {res}\")\n",
    "\n",
    "  top_row =  pd.DataFrame({'FPR':0, 'TPR':0}, index=[1.0])\n",
    "  final_roc_coordinates = {}\n",
    "  for model_key in model_dict:\n",
    "    final_roc_coordinates[model_key] = pd.concat([top_row, all_roc_coordinates[model_key]]).astype('float')\n",
    "\n",
    "  return final_roc_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {'RandomForest':rfc, \n",
    "              'KNN':knn,\n",
    "              'LinearRegression':lr,\n",
    "              'SVC':svc,\n",
    "              'XGB':xgb\n",
    "              }\n",
    "final_roc = generate_roc_coordinates(all_models, x_val, y_val)\n",
    "plot_roc(dict(final_roc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30244d2f3efd454410fd1ae01f00644ee295ec6a10c22f1f9cb3171fed2f7775"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
